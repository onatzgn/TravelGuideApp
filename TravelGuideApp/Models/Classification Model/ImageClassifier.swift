import CoreML
import Vision
import UIKit

class ImageClassifier {
    // CoreML modelini ve Vision modelini tutan deÄŸiÅŸkenler
    private var mlModel: MLModel
    private var visionModel: VNCoreMLModel

    // SÄ±nÄ±f etiketlerini tutan deÄŸiÅŸken
    private var classLabels: [String] = []

    // Sabit (hardcoded) etiket listesi - fallback iÃ§in
    private let hardcodedLabels = [
        "alman_cesmesi", "ayasofya", "bozdogan_kemeri", "cemberlitas",
        "dikilitas", "galata_kulesi", "kadikoy_boga_heykeli", "kiz_kulesi",
        "medusa", "ortakoy_cami", "sultanahmet", "taksim_cumhuriyet_aniti",
        "topkapi_sarayi", "yilanli_sutun"
    ]

    init() {
        do {
            // 1. MLModel'i yÃ¼kle
            // Not: 'place_recognition_model_updated3' projenizdeki Core ML model sÄ±nÄ±fÄ±nÄ±n adÄ± olmalÄ±.
            let configuration = MLModelConfiguration() // Gerekirse konfigÃ¼rasyon ayarlarÄ± eklenebilir
            self.mlModel = try place_recognition_model_updated3(configuration: configuration).model

            // 2. Vision iÃ§in VNCoreMLModel oluÅŸtur
            self.visionModel = try VNCoreMLModel(for: self.mlModel)

            // 3. SÄ±nÄ±f etiketlerini model aÃ§Ä±klamasÄ±ndan almayÄ± dene
            if let labels = self.mlModel.modelDescription.classLabels, !labels.isEmpty {
                 self.classLabels = labels.compactMap { $0 as? String }
                 print("âœ… Etiketler model aÃ§Ä±klamasÄ±ndan baÅŸarÄ±yla alÄ±ndÄ±: \(self.classLabels.count) adet.")
            } else {
                 // AlÄ±namazsa veya boÅŸsa sabit listeyi kullan
                 print("âš ï¸ Model aÃ§Ä±klamasÄ±nda etiket bulunamadÄ± veya boÅŸ, sabit liste kullanÄ±lÄ±yor.")
                 self.classLabels = hardcodedLabels
            }

            // Etiket sayÄ±sÄ± kontrolÃ¼ (opsiyonel ama faydalÄ±)
            if let outputDescription = self.mlModel.modelDescription.outputDescriptionsByName.first?.value,
               let shapeConstraint = outputDescription.multiArrayConstraint {
                let outputCount = shapeConstraint.shape.last?.intValue ?? 0
                if outputCount > 0 && outputCount != self.classLabels.count {
                     print("â€¼ï¸ UYARI: Modelin Ã§Ä±kÄ±ÅŸ boyutu (\(outputCount)) ile etiket sayÄ±sÄ± (\(self.classLabels.count)) eÅŸleÅŸmiyor!")
                }
            }


        } catch {
            fatalError("âŒ CoreML modeli yÃ¼klenemedi veya VNCoreMLModel oluÅŸturulamadÄ±: \(error.localizedDescription)")
        }
    }

    /// Verilen bir UIImage'i sÄ±nÄ±flandÄ±rÄ±r ve sonucu completion handler ile dÃ¶ndÃ¼rÃ¼r.
    /// - Parameters:
    ///   - image: SÄ±nÄ±flandÄ±rÄ±lacak UIImage nesnesi.
    ///   - imageName: Hata ayÄ±klama loglarÄ± iÃ§in gÃ¶rÃ¼ntÃ¼nÃ¼n adÄ± (opsiyonel).
    ///   - completion: Sonucu (tahmin edilen etiket, gÃ¼ven skoru) veya hata durumunu dÃ¶ndÃ¼ren closure.
    func classify(image: UIImage, imageName: String = "Image", completion: @escaping (String, Double) -> Void) {
        print("ğŸ“· \(imageName): SÄ±nÄ±flandÄ±rma baÅŸlÄ±yor...")

        // 1. GÃ¶rÃ¼ntÃ¼yÃ¼ yeniden boyutlandÄ±r (Modele uygun hale getir)
        print("ğŸ” GÃ¶rÃ¼ntÃ¼ yeniden boyutlandÄ±rÄ±lÄ±yor (224x224)...")
        let resizedImage = image.stretchedTo(size: CGSize(width: 224, height: 224))

        // 2. UIImage'i CIImage'a dÃ¶nÃ¼ÅŸtÃ¼r
        guard let ciImage = CIImage(image: resizedImage) else {
            print("âŒ UIImage -> CIImage dÃ¶nÃ¼ÅŸÃ¼mÃ¼ baÅŸarÄ±sÄ±z.")
            completion("Error: CIImage Conversion Failed", 0.0)
            return
        }

        // 3. VNCoreMLRequest oluÅŸtur
        print("ğŸ“¦ VNCoreMLRequest oluÅŸturuluyor...")
        let request = VNCoreMLRequest(model: visionModel) { [weak self] request, error in
            // ZayÄ±f referans kullanarak olasÄ± retain cycle'Ä± Ã¶nle
             guard let self = self else { return }

            // Hata kontrolÃ¼
            if let error = error {
                print("âŒ VNCoreMLRequest iÅŸlenirken hata oluÅŸtu: \(error.localizedDescription)")
                DispatchQueue.main.async {
                    completion("Error: Request Failed", 0.0)
                }
                return
            }

            // SonuÃ§larÄ± iÅŸle
            self.processResults(for: request, completion: completion)
        }

        // Ä°steÄŸe baÄŸlÄ±: GÃ¶rÃ¼ntÃ¼ kÄ±rpma ve Ã¶lÃ§ekleme seÃ§eneklerini Vision'a bÄ±rakmak iÃ§in
        // request.imageCropAndScaleOption = .scaleFill // veya .centerCrop vs.

        // 4. VNImageRequestHandler oluÅŸtur ve isteÄŸi gerÃ§ekleÅŸtir
        print("ğŸ› ï¸ VNImageRequestHandler hazÄ±rlanÄ±yor ve istek gÃ¶nderiliyor...")
        let handler = VNImageRequestHandler(ciImage: ciImage, orientation: image.cgImagePropertyOrientation)
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                try handler.perform([request])
                print("ğŸš€ SÄ±nÄ±flandÄ±rma isteÄŸi baÅŸarÄ±yla gÃ¶nderildi ve iÅŸleniyor...")
            } catch {
                print("âŒ VNImageRequestHandler.perform sÄ±rasÄ±nda hata oluÅŸtu: \(error.localizedDescription)")
                DispatchQueue.main.async {
                    completion("Error: Handler Failed", 0.0)
                }
            }
        }
    }

    /// VNCoreMLRequest sonuÃ§larÄ±nÄ± iÅŸleyen yardÄ±mcÄ± fonksiyon.
    private func processResults(for request: VNRequest, completion: @escaping (String, Double) -> Void) {
        // 1. VNClassificationObservation KONTROLÃœ (En OlasÄ± Durum - Classifier olarak tanÄ±mlanmÄ±ÅŸsa)
        if let results = request.results as? [VNClassificationObservation], let topResult = results.first {
            let rawConfidences = results.map { Double($0.confidence) }
            let maxConfidence = rawConfidences.max() ?? 0

            // EÄŸer confidence 1.0'dan bÃ¼yÃ¼kse bu deÄŸerler logit'tir â†’ Softmax uygulanmamÄ±ÅŸ demektir
            if maxConfidence > 1.0 {
                print("âš ï¸ UyarÄ±: VNClassificationObservation confidence > 1.0 â€” manuel softmax uygulanÄ±yor...")

                // Softmax uygula
                let stabilized = rawConfidences.map { $0 - maxConfidence }
                let expValues = stabilized.map { exp($0) }
                let sumExp = expValues.reduce(0, +)
                let softmax = expValues.map { $0 / sumExp }

                print("ğŸ” Manuel Softmax SonuÃ§larÄ±:")
                for (index, score) in softmax.enumerated() {
                    print("  - \(results[index].identifier): \(String(format: "%.2f%%", score * 100))")
                }

                if let maxIndex = softmax.indices.max(by: { softmax[$0] < softmax[$1] }) {
                    let predictedLabel = results[maxIndex].identifier
                    let confidence = softmax[maxIndex]
                    print("âœ… En iyi tahmin (Manuel Softmax): \(predictedLabel), GÃ¼ven: \(String(format: "%.2f%%", confidence * 100))")
                    if confidence < 0.75 {
                        print("â— GÃ¼ven skoru %75'in altÄ±nda. Tahmin geÃ§ersiz sayÄ±lÄ±yor. (GÃ¼ven: \(String(format: "%.2f%%", confidence * 100)))")
                        DispatchQueue.main.async {
                            completion("unknown", confidence)
                        }
                    } else {
                        DispatchQueue.main.async {
                            completion(predictedLabel, confidence)
                        }
                    }
                } else {
                    print("âŒ Manuel Softmax sonrasÄ± en iyi tahmin bulunamadÄ±.")
                    DispatchQueue.main.async {
                        completion("Error: Softmax ArgMax Failed", 0.0)
                    }
                }

                return // Manuel softmax kullanÄ±ldÄ±
            }

            // Softmax doÄŸru ÅŸekilde uygulanmÄ±ÅŸsa doÄŸrudan kullan
            print("âœ… SonuÃ§lar VNClassificationObservation olarak alÄ±ndÄ± (Softmax CoreML tarafÄ±ndan uygulanmÄ±ÅŸ).")
            let identifier = topResult.identifier
            let confidence = Double(topResult.confidence)

            print("ğŸ” TÃ¼m Tahminler (CoreML'den gelen):")
            results.prefix(5).forEach { observation in
                print("  - \(observation.identifier): \(String(format: "%.2f%%", observation.confidence * 100))")
            }

            print("âœ… En iyi tahmin: \(identifier), GÃ¼ven: \(String(format: "%.2f%%", confidence * 100))")
            if confidence < 0.75 {
                print("â— GÃ¼ven skoru %75'in altÄ±nda. Tahmin geÃ§ersiz sayÄ±lÄ±yor. (GÃ¼ven: \(String(format: "%.2f%%", confidence * 100)))")
                DispatchQueue.main.async {
                    completion("unknown", confidence)
                }
            } else {
                DispatchQueue.main.async {
                    completion(identifier, confidence)
                }
            }
            return
        }

        // 2. VNCoreMLFeatureValueObservation KONTROLÃœ (Fallback - Genel model Ã§Ä±kÄ±ÅŸÄ± veya classifier olmayan durumlar)
        if let results = request.results as? [VNCoreMLFeatureValueObservation],
           let multiArray = results.first?.featureValue.multiArrayValue {
            print("âš ï¸ VNClassificationObservation alÄ±namadÄ±, VNCoreMLFeatureValueObservation ile manuel Softmax yapÄ±lÄ±yor...")

            // MLMultiArray'den Float dizisine dÃ¶nÃ¼ÅŸtÃ¼r
            guard let pointer = try? UnsafeBufferPointer<Float32>(multiArray) else {
                print("âŒ MLMultiArray verisi Float32 dizisine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lemedi.")
                DispatchQueue.main.async { completion("Error: MultiArray Conversion", 0.0) }
                return
            }
            let floatArray = Array(pointer) // Ham Ã§Ä±kÄ±ÅŸlar (logits)

             // Etiket sayÄ±sÄ± ile Ã§Ä±kÄ±ÅŸ sayÄ±sÄ± kontrolÃ¼
             if self.classLabels.count != floatArray.count {
                 print("âŒ Etiket sayÄ±sÄ± (\(self.classLabels.count)) ile model Ã§Ä±kÄ±ÅŸ sayÄ±sÄ± (\(floatArray.count)) eÅŸleÅŸmiyor!")
                 // Modelin son katmanÄ±nÄ± veya etiket listesini kontrol edin.
                 // En iyi ihtimalle devam etmeyi deneyebiliriz ama muhtemelen yanlÄ±ÅŸ sonuÃ§ verir.
                 // completion("Error: Label/Output Mismatch", 0.0)
                 // return // Veya riski alÄ±p devam et
             }

            // ---- Manuel Softmax UygulamasÄ± ----
            // Stabilize etmek iÃ§in en bÃ¼yÃ¼k logit'i Ã§Ä±kar (sayÄ±sal stabilite iÃ§in)
            let maxLogit = floatArray.max() ?? 0
            let stabilized = floatArray.map { $0 - maxLogit }
            // Ãœstel deÄŸerleri hesapla
            let expValues = stabilized.map { expf($0) }
            // Ãœstel deÄŸerlerin toplamÄ±nÄ± hesapla
            let sumExp = expValues.reduce(0, +)
            // Softmax olasÄ±lÄ±klarÄ±nÄ± hesapla (eÄŸer toplam 0 deÄŸilse)
            let softmax = sumExp > 0 ? expValues.map { $0 / sumExp } : Array(repeating: 1.0 / Float(expValues.count), count: expValues.count) // Toplam 0 ise eÅŸit daÄŸÄ±t
            // ---- Manuel Softmax Sonu ----


            print("ğŸ” Manuel Softmax SonuÃ§larÄ±:")
            for (index, score) in softmax.enumerated() {
                // GÃ¼venlik kontrolÃ¼: index'in labels dizisinin sÄ±nÄ±rlarÄ± iÃ§inde olduÄŸundan emin ol
                if index < self.classLabels.count {
                    print("  - \(self.classLabels[index]): \(String(format: "%.2f%%", score * 100))")
                } else {
                    print("  - Index \(index) etiket listesi sÄ±nÄ±rlarÄ± dÄ±ÅŸÄ±nda!")
                }
            }

            // En yÃ¼ksek olasÄ±lÄ±ÄŸa sahip indeksi ve etiketi bul
            if let maxIndex = softmax.indices.max(by: { softmax[$0] < softmax[$1] }), maxIndex < self.classLabels.count { // SÄ±nÄ±r kontrolÃ¼ ekle
                let predictedLabel = self.classLabels[maxIndex]
                let confidence = softmax[maxIndex]
                print("âœ… En iyi tahmin (Manuel Softmax): \(predictedLabel), GÃ¼ven: \(String(format: "%.2f%%", confidence * 100))")
                if confidence < 0.75 {
                    print("â— GÃ¼ven skoru %75'in altÄ±nda. Tahmin geÃ§ersiz sayÄ±lÄ±yor. (GÃ¼ven: \(String(format: "%.2f%%", confidence * 100)))")
                    DispatchQueue.main.async {
                        completion("unknown", Double(confidence))
                    }
                } else {
                    DispatchQueue.main.async {
                        completion(predictedLabel, Double(confidence))
                    }
                }
            } else {
                print("âŒ Manuel Softmax sonrasÄ± en iyi tahmin bulunamadÄ± veya index sÄ±nÄ±r dÄ±ÅŸÄ±nda.")
                DispatchQueue.main.async { completion("Error: Softmax ArgMax Failed", 0.0) }
            }
            return // Ä°ÅŸlem tamamlandÄ±
        }

        // HÄ°Ã‡BÄ°R UYGUN SONUÃ‡ FORMATI ALINAMAZSA
        print("âŒ VNCoreMLRequest beklenen formatta sonuÃ§ dÃ¶ndÃ¼rmedi (Ne VNClassificationObservation ne de VNCoreMLFeatureValueObservation). Modelin Ã§Ä±ktÄ±larÄ±nÄ± kontrol edin.")
        DispatchQueue.main.async {
            completion("Error: No Valid Results", 0.0)
        }
    }

    // Hata ayÄ±klama iÃ§in piksel analizi fonksiyonu (isteÄŸe baÄŸlÄ±)
    private func analyzeImagePixels(_ image: UIImage) {
        guard let cgImage = image.cgImage else {
            print("âŒ CGImage alÄ±namadÄ±")
            return
        }

        let width = cgImage.width
        let height = cgImage.height
        // Bu kÄ±sÄ±m genellikle Core ML'in otomatik yaptÄ±ÄŸÄ± Ã¶n iÅŸlemeyi manuel olarak simÃ¼le etmek iÃ§indir.
        // Modelin ct.ImageType iÃ§inde tanÄ±mlanan scale ve bias ile Ã¶n iÅŸleme yapmasÄ± beklenir.
        // Bu fonksiyon sadece bilgi amaÃ§lÄ±dÄ±r, modelin asÄ±l girdisini etkilemez.
        print("ğŸ”¬ Piksel Analizi (Bilgi AmaÃ§lÄ±): \(width)x\(height)")
        // ... (Ã–nceki kodunuzdaki piksel okuma ve ortalama hesaplama kÄ±smÄ± buraya eklenebilir) ...
    }
}

// MARK: - UIImage Extensions

extension UIImage {
    /// UIImage'in yÃ¶nelimini Vision framework'Ã¼nÃ¼n anlayacaÄŸÄ± CGImagePropertyOrientation'a Ã§evirir.
    var cgImagePropertyOrientation: CGImagePropertyOrientation {
        switch imageOrientation {
        case .up: return .up
        case .down: return .down
        case .left: return .left
        case .right: return .right
        case .upMirrored: return .upMirrored
        case .downMirrored: return .downMirrored
        case .leftMirrored: return .leftMirrored
        case .rightMirrored: return .rightMirrored
        @unknown default:
            print("âš ï¸ Bilinmeyen UIImage.Orientation deÄŸeri, varsayÄ±lan olarak .up kullanÄ±lÄ±yor.")
            return .up
        }
    }

    /// UIImage'i belirtilen boyuta, en/boy oranÄ±nÄ± korumadan esneterek yeniden boyutlandÄ±rÄ±r.
    /// - Parameter targetSize: Hedef boyut (CGSize).
    /// - Returns: Yeniden boyutlandÄ±rÄ±lmÄ±ÅŸ UIImage veya iÅŸlem baÅŸarÄ±sÄ±z olursa orijinal gÃ¶rÃ¼ntÃ¼.
    func stretchedTo(size targetSize: CGSize) -> UIImage {
        // UIGraphicsBeginImageContextWithOptions genellikle daha iyi kalite sunar.
        // opaque: false -> Alfa kanalÄ±nÄ± koru
        // scale: self.scale -> Retina ekranlarda pikselleÅŸmeyi Ã¶nle (veya model 1x bekliyorsa 1.0)
        // Modelinizin 224x224@1x beklediÄŸini varsayarsak scale: 1.0 daha doÄŸru olabilir.
        // Emin deÄŸilseniz self.scale kullanmak genellikle gÃ¼venlidir.
        UIGraphicsBeginImageContextWithOptions(targetSize, false, 1.0) // scale'i 1.0 olarak deÄŸiÅŸtirdim.
        self.draw(in: CGRect(origin: .zero, size: targetSize))
        let newImage = UIGraphicsGetImageFromCurrentImageContext()
        UIGraphicsEndImageContext()
        return newImage ?? self // BaÅŸarÄ±sÄ±z olursa orijinali dÃ¶ndÃ¼r
    }
}
